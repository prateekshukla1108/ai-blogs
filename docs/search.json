[
  {
    "objectID": "docs/posts/Liner-Regression.html",
    "href": "docs/posts/Liner-Regression.html",
    "title": "Prateek's Blog",
    "section": "",
    "text": "Redirect"
  },
  {
    "objectID": "posts/Liner-Regression.html",
    "href": "posts/Liner-Regression.html",
    "title": "Demystifying Liner Regression with the Feynman Method",
    "section": "",
    "text": "Demystifying Linear Regression with the Feynman Method\nLinear regression is one of the simplest yet most powerful tools in the arsenal of a data scientist. It’s the humble bread and butter of predictive modeling—but understanding it deeply? That’s where the magic lies. Today, I’m going to walk you through linear regression using the Feynman method. Why? Because if there’s one thing Richard Feynman taught us, it’s that simplicity and clarity go hand in hand with mastery.\n\nWhat Is the Feynman Method?\nBefore diving into the math, let’s talk about the methodology. The Feynman Method consists of four steps: 1. Understand the concept and explain it clearly in simple terms. 2. Identify gaps in your understanding. 3. Go back to the source material to fill the gaps. 4. Simplify further until you can explain it to a child.\nWith this framework in mind, let’s tackle linear regression.\n\n\nStep 1: Understanding Linear Regression\nAt its core, linear regression is a way to find the best-fit straight line through a set of data points. This line helps us understand relationships and make predictions. The mathematical representation is straightforward:\n\\[y = β₀ + β₁x + ε\\]\nWhere: - \\(y\\): The dependent variable (what you’re trying to predict). - \\(x\\): The independent variable (your predictor). - \\(β₀\\): The intercept (where the line crosses the y-axis). - \\(β₁\\): The slope (how much \\(y\\) changes for a unit change in \\(x\\)). - \\(ε\\): The error term (real-world data isn’t perfect!).\nThink of it like ordering pizza: \\(y\\) is the total cost, \\(x\\) is the number of pizzas, \\(β₁\\) is the price per pizza, and \\(β₀\\) is the delivery fee.\nIf data analysis is pizza, then linear regression is like asking, “How much of this cost is the pizza and how much is me being too lazy to cook?”\n\n\nStep 2: Identifying Gaps\nNow, let’s test our understanding. If I ask, “Why do we use the least squares method to fit the line?” can you explain it? If not, there’s a gap to fill.\nThe least squares method minimizes the sum of squared differences between the observed values and the values predicted by our line. Squaring the differences ensures we’re penalizing large errors more heavily and makes the math nice and continuous for optimization.\n\n\nStep 3: Filling the Gaps\nTo dive deeper, let’s derive the equations for \\(β₀\\) and \\(β₁\\):\n\\[β₁ = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\]\n\\[β₀ = \\bar{y} - β₁\\bar{x}\\]\nThese equations come from calculus and linear algebra, but their meaning is intuitive: - \\(β₁\\) tells us how strongly \\(x\\) and \\(y\\) move together. - \\(β₀\\) adjusts for the baseline when \\(x\\) is zero.\n\n\nStep 4: Explaining It Simply\nImagine you’re a kid playing with a garden hose. The water (\\(y\\)) sprays farther when you tilt the nozzle upward (\\(x\\)). Linear regression is like figuring out how much more distance you get with each tilt, while accounting for the fact that sometimes the hose just leaks water everywhere (\\(ε\\)).\nLinear regression: the only time in life where trying to minimize your “mistakes” actually makes you look smarter.\n\n\nWhy It’s Powerful\nLinear regression is not just for straight-line relationships. It’s a foundation. Mastering it is like learning scales before playing a symphony. Want to add more predictors? Extend to multiple linear regression. Want to model curves? Polynomial regression has your back.\n\n\nApplications\nFrom predicting house prices to understanding the effect of study hours on exam scores, linear regression is everywhere. But remember—always check the assumptions: linearity, independence, homoscedasticity, and normality of errors.\n\n\nConclusion\nLinear regression may be simple, but simplicity is a virtue. As Feynman would say, “If you can’t explain it simply, you don’t understand it well enough.” So, grab some data, fit a line, and never underestimate the power of asking simple questions and looking for simple answers.\nAnd remember: models come and go, but a bad fit stays forever!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blogs on Neural Networks, Machine Learning and Deep Learning",
    "section": "",
    "text": "How to write CUDA kernels without actually having a GPU\n\n\n \n\n\nCUDA-Programming\n\n\n \n\nGuide to using LeetGPU and Colab to write CUDA Kernels\n\n\n\nFeb 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDemystifying Liner Regression with the Feynman Method\n\n\n \n\n\nMachine Learning\n\n\n \n\nExplaining Liner Regression in Simplest way\n\n\n\nDec 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to setup WSL, Python and PyTorch for Deep Learning\n\n\n \n\n\ncomputer_usage\n\n\n \n\nGuide to install dependencies for Deep Learning.\n\n\n\nNov 13, 2024\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The purpose of this blog is to de-jargonize and simplify complex topics into understandable bits while exploring important topics on a Deep Level."
  },
  {
    "objectID": "posts/Installing-Dependencies.html",
    "href": "posts/Installing-Dependencies.html",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "",
    "text": "WSL implies for Windows Subsystem for Linux (WSL), where you can run a Linux environment on your Windows machine without the hassle of dual-booting or setting up a virtual machine. This guide will take you through the steps to install WSL, focusing on WSL 2, which is faster, better, and more compatible than its predecessor.\nThe basic prerequisits are that You need Windows 10 version 2004 or higher (Build 19041 and above) or Windows 11. If you’re still rocking an older version, it might be time for an upgrade—like swapping out your flip phone for a smartphone!\nIf you get any error related to virtualization. You need to have virtualization enabled which you can do by enabling Hyper V in your device\n\n\nOpen PowerShell as Administrator: Search for “PowerShell” in the Start menu. Right-click on it and select “Run as administrator”. If you get intimidated by the black screen don’t panik you are inside terminal which helps us to execute commands. More on it later! Run the Installation Command: In the PowerShell window, type the following command and press Enter\nwsl --install\nThis command will enable all the necessary features for WSL, download the Linux Kernel, and install Ubuntu as your default distribution. A restart may be required.\nIf ubuntu is not your cup of tea then you can choose another distribution by\nwsl --install -d Debian\nfor debian\n\n\n\nAfter installation, launch your installed Linux distribution from the Start menu\nYou’ll be prompted to create a username and password. Choose wisely this is your secret identity! Remember, while typing your password, nothing will appear on the screen; this is normal behavior in Linux. It’s not broken; it’s just shy.\n\n\n\nNow that you’ve got your Linux environment set up, let’s make sure it’s up to date: you can do that by just typing\nsudo apt update\nsudo apt upgrade"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-1-enable-wsl",
    "href": "posts/Installing-Dependencies.html#step-1-enable-wsl",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "",
    "text": "Open PowerShell as Administrator: Search for “PowerShell” in the Start menu. Right-click on it and select “Run as administrator”. If you get intimidated by the black screen don’t panik you are inside terminal which helps us to execute commands. More on it later! Run the Installation Command: In the PowerShell window, type the following command and press Enter\nwsl --install\nThis command will enable all the necessary features for WSL, download the Linux Kernel, and install Ubuntu as your default distribution. A restart may be required.\nIf ubuntu is not your cup of tea then you can choose another distribution by\nwsl --install -d Debian\nfor debian"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-2-make-a-user-account",
    "href": "posts/Installing-Dependencies.html#step-2-make-a-user-account",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "",
    "text": "After installation, launch your installed Linux distribution from the Start menu\nYou’ll be prompted to create a username and password. Choose wisely this is your secret identity! Remember, while typing your password, nothing will appear on the screen; this is normal behavior in Linux. It’s not broken; it’s just shy."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-4-update-the-system",
    "href": "posts/Installing-Dependencies.html#step-4-update-the-system",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "",
    "text": "Now that you’ve got your Linux environment set up, let’s make sure it’s up to date: you can do that by just typing\nsudo apt update\nsudo apt upgrade"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#some-basic-definitions-and-tools-handy-in-cli",
    "href": "posts/Installing-Dependencies.html#some-basic-definitions-and-tools-handy-in-cli",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Some basic definitions and tools handy in cli",
    "text": "Some basic definitions and tools handy in cli\nSo here are some popular commands and definitions which we need to keep in mind while we use CLI\ndirectory - for most cases directory is your ‘folder’ we can store different files and directories in a directory.\nls : Lists the contents of a directory. Use options like -a for hidden files or -l for detailed information.\ncd [directory]: Changes the current directory to the specified one. Use cd .. to go back\nmkdir [dirname]: Creates a new directory with the specified name.\nrm -rf [dirname] : Removes a directory and everything in it. This is done without confirmation so know what you are doing"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-1-install-wget-in-you-system",
    "href": "posts/Installing-Dependencies.html#step-1-install-wget-in-you-system",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 1: Install wget in you system",
    "text": "Step 1: Install wget in you system\nyou can do so by executing -\nsudo apt install wget"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-2-download-the-setup-script-for-miniforge",
    "href": "posts/Installing-Dependencies.html#step-2-download-the-setup-script-for-miniforge",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 2: Download the setup script for miniforge",
    "text": "Step 2: Download the setup script for miniforge\nyou can do that by following these commands\n\nfor x86_64\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\n\n\nfor arm\nwget https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-aarch64.sh\nthis will download the Miniforge installer in your WSL"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-3-install-miniforge-in-your-wsl",
    "href": "posts/Installing-Dependencies.html#step-3-install-miniforge-in-your-wsl",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 3: Install miniforge in your WSL",
    "text": "Step 3: Install miniforge in your WSL\nexecute the following command -\n\nFor x86_64\nbash Miniforge3-Linux-x86_64.sh\n\n\nFor Arm\nbash Miniforge3-Linux-aarch64.sh\nA simple setup will appear which will ask you to accept the licence agreement\nThen a prompt will appear telling you that setup will install miniforge in your home directory say yes to it\nAnd then miniforge will install not only python but a whole bunch of libraries which will come handy to us later.\nrestart you shell by executing bash to make it initialize miniforge"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-4-agree-to-initialize-it",
    "href": "posts/Installing-Dependencies.html#step-4-agree-to-initialize-it",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 4: Agree to initialize it",
    "text": "Step 4: Agree to initialize it\nIt will ask you if you want to initialize it whenever you start your machine and say yes to it.\nWhat it will do is that it will execute python everytime we launch wsl"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#mamba-and-conda",
    "href": "posts/Installing-Dependencies.html#mamba-and-conda",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Mamba and conda",
    "text": "Mamba and conda\nMamba and Conda are both powerful tools used for package and environment management in Python. They install everything we need for python and help us create virtual environments. This brings us to - ## Step 5: Enable virtual environment\nA virtual environment is a self-contained directory that allows you to manage dependencies for different projects without stepping on each other’s toes. It will help seperate python we need with the system python\nTo create a virtual environment just execute:\nmamba create -n dl_env python=3.9\nthis will create a python virtual environment\nbut that’s not all we also need to activate it for it to work this is done by executing\nmamba activate dl_env\n\nA pro tip - You can activate the virtual environment everytime you want by putting it in your .bashrc file. You can do that by\n\nnano .bashrc\nthis opens a text editor which we will use to edit files. Edit it by adding mamba activate dl_env at the end of the file.\nthen press ctrl + x to exit and y to save the file."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-6-installing-ipython-and-jupyter-lab",
    "href": "posts/Installing-Dependencies.html#step-6-installing-ipython-and-jupyter-lab",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 6: Installing ipython and jupyter lab",
    "text": "Step 6: Installing ipython and jupyter lab\n\nNeed for these tools\nIf you’re ready to kick your AI game up a notch, you need to get cozy with IPython and JupyterLab. We have so many good reasons to use these tools\nWe will use Ipython because\n\nIt helps us to display media like Images, Videos etc\nIPython includes special commands (prefixed with % or %%) that allow you to perform tasks like timing execution or running shell commands seamlessly.\nWith improved tracebacks and debugging capabilities, it makes troubleshooting easier.\n\nWe will use Jupyter Lab because -\n\nMulti document UI - Open multiple notebooks, text files, and terminals all at once. You can juggle your projects too. No more switching tabs.\nExtensions Galore: Want to customize your experience? JupyterLab supports extensions that let you add new features or integrate with other tools. It’s like dressing up your notebook in the latest fashion make it yours\nInteractive Widgets: Create interactive visualizations and controls right in your notebooks. Want to tweak parameters on the fly? Just slide those sliders.\n\nBasically they help is making the experiance smoother for the journey. ### Installation\nHere is the command to install these tools -\nmamba install ipython jupyterlab"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#step-7-install-pytorch",
    "href": "posts/Installing-Dependencies.html#step-7-install-pytorch",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Step 7: Install pytorch",
    "text": "Step 7: Install pytorch\nPyTorch is a powerful and flexible tool for deep learning and machine learning projects. Here are some of its features\n\nDynamic Computation Graphs: Allows changes to the model on-the-fly, making debugging easier.\nTensor Operations: Supports efficient tensor computations with GPU acceleration for faster processing.\nUser-Friendly: Intuitive and Pythonic interface, great for beginners and experienced users alike.\nRich Ecosystem: Includes libraries for building neural networks and optimization, simplifying model development.\nStrong Community: Extensive documentation and active community support for learning and troubleshooting.\n\n\nInstallation\nHere is how to get it installed -\n\nFor devices with Nvidia GPU - if your device have an Nvidia GPU then you can install pytorch with CUDA support by executing following command -\n\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia\nYou will also need to install the cuda toolkit for pytorch to work. You can do it by executing -\n\nwget https://developer.download.nvidia.com/compute/cuda/12.6.2/local_installers/cuda_12.6.2_560.35.03_linux.run\nThen run\nsudo sh cuda_12.6.2_560.35.03_linux.run\n\nFor devices with integrated graphics - If you are poor student like me and have device with integrated graphics then you should install pytorch by using following command -\n\nmamba install pytorch torchvision torchaudio cpuonly -c pytorch\nAnd you have successfully installed the tools required for deep learning."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#vim",
    "href": "posts/Installing-Dependencies.html#vim",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Vim",
    "text": "Vim\nVim is the most supereme cli text editor that one can use in linux. Here is how to install and use it\n\nOpen WSL Terminal:\n\nLaunch your WSL terminal.\n\nUpdate Package List:\n\nBefore installing any software, update the package list by running:\nsudo apt update\n\nInstall Vim:\n\nInstall Vim by executing the following command:\nsudo apt install vim -y\nThis command retrieves and installs Vim along with its necessary components.\n\nLaunching Vim:\n\nTo create or edit a file, use the command:\nvim filename.txt\nReplace filename.txt with your desired file name. If the file does not exist, Vim will create it.\n\nBasic Navigation and Editing:\n\nUpon opening a file, you start in Normal mode. Press i to switch to Insert mode, where you can type text.\nTo return to Normal mode, press Esc.\nYou can go up down left and right in the document by either using arrow keys or using h,j,k,l keys (right,down,up,left).\n\nSaving and Exiting:\n\nTo save changes, type :w and press Enter.\nTo exit Vim, type :q and press Enter. If you want to save and exit simultaneously, type :wq."
  },
  {
    "objectID": "posts/Installing-Dependencies.html#ranger",
    "href": "posts/Installing-Dependencies.html#ranger",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Ranger",
    "text": "Ranger\nRanger is a cli file manager which you can use to navigate through files easily.\nTo install and use Ranger, a VIM-inspired file manager, in Windows Subsystem for Linux (WSL), follow these detailed steps:"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#installation-steps",
    "href": "posts/Installing-Dependencies.html#installation-steps",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Installation Steps",
    "text": "Installation Steps\n\nOpen WSL Terminal:\n\nLaunch your WSL terminal\n\nInstall Prerequisites:\n\nUpdate the package list and install the necessary packages (make, git, and vim) by running:\nsudo apt update\nsudo apt install make git vim -y\n\nInstall Ranger:\nsudo apt install ranger -y\nConfigure Ranger:\n\nRun Ranger once to create the configuration directory:\nranger"
  },
  {
    "objectID": "posts/Installing-Dependencies.html#using-ranger",
    "href": "posts/Installing-Dependencies.html#using-ranger",
    "title": "How to setup WSL, Python and PyTorch for Deep Learning",
    "section": "Using Ranger",
    "text": "Using Ranger\n\nLaunching Ranger:\n\nStart Ranger by typing:\nranger\n\nInterface Overview:\n\nThe interface is divided into three columns:\n\nLeft Column: Displays the parent directory.\nMiddle Column: Shows contents of the current directory.\nRight Column: Provides a preview of the selected file or folder.\n\n\nBasic Navigation:\n\nUse the following keys to navigate:\n\nArrow keys or h, j, k, l for left, down, up, and right respectively.\nEnter to open a file or directory.\nq to quit.\n\n\n\n\nCopying, Pasting, and Deleting Files\n\nCopying Files:\n\nTo copy a file or directory, navigate to it and press yy (yank).\nTo copy multiple files, select them using Space and then press yy.\n\nPasting Files:\n\nNavigate to the destination directory and press p to paste the copied files.\n\nDeleting Files:\n\nTo delete a file or directory, navigate to it and press dd (delete).\nConfirm the deletion when prompted."
  },
  {
    "objectID": "posts/CUDA-for-poor-people.html",
    "href": "posts/CUDA-for-poor-people.html",
    "title": "How to write CUDA kernels without actually having a GPU",
    "section": "",
    "text": "Behold, you seekers of knowledge of CUDA! You who stand before the challenge of parallel processing, yearning for jobs of CUDA programming yet finding your hardware lacking! What is a developer to do when faced with such a challenge? With platforms like colab and leetgpu, We no longer need to resign ourselves to the sequential nature of our CPUs. Here’s how to use them. This is for people who don’t have a device with GPU and can’t afford to ssh into a paid cloud server."
  },
  {
    "objectID": "posts/CUDA-for-poor-people.html#setting-up-cuda-in-colab",
    "href": "posts/CUDA-for-poor-people.html#setting-up-cuda-in-colab",
    "title": "How to write CUDA kernels without actually having a GPU",
    "section": "Setting Up CUDA in Colab",
    "text": "Setting Up CUDA in Colab\n\nCreate a new Colab notebook\nEnable GPU runtime:\n\nNavigate to Runtime &gt; Change runtime type\nSelect GPU from the Hardware accelerators dropdown\n\nVerify GPU access by running:\n!nvidia-smi\nNote: The ! prefix allows you to run shell commands in Colab.\nWrite and execute CUDA code:\n# Write CUDA code to a file\ncuda_code = '''\n#include &lt;stdio.h&gt;\n\n__global__ void hello_cuda() {\n    printf(\"Hello from block %d, thread %d\\\\n\", \n           blockIdx.x, threadIdx.x);\n}\n\nint main() {\n    hello_cuda&lt;&lt;&lt;2, 4&gt;&gt;&gt;();\n    cudaDeviceSynchronize();\n    return 0;\n}\n'''\n\n# Save to file\nwith open('hello.cu', 'w') as f:\n    f.write(cuda_code)\n\n# Compile and run\n!nvcc hello.cu -o hello_cuda\n!./hello_cuda"
  },
  {
    "objectID": "posts/CUDA-for-poor-people.html#important-considerations-for-colab",
    "href": "posts/CUDA-for-poor-people.html#important-considerations-for-colab",
    "title": "How to write CUDA kernels without actually having a GPU",
    "section": "Important Considerations for Colab",
    "text": "Important Considerations for Colab\n\nString Formatting: When writing CUDA code in Python strings, you need to escape certain characters:\n\nUse \\\\n instead of \\n for newlines\nUse forward slashes for file paths (my_code/kernel.cu) instead of backslashes\n\nGPU Performance: Free tier users get access to less powerful GPUs like the P100, which offers lower performance compared to LeetGPU’s RTX 3070.\nArchitecture-Specific Compilation: For complex kernels with memory management, specify the target architecture during compilation:\nnvcc -o myprogram -arch=sm_70 myprogram.cu\nThe -arch=sm_70 flag targets the GPU architecture available in your Colab instance.\n\nBy using these platforms, you can develop your CUDA programming skills without investing in dedicated hardware. Each option has its trade-offs, so choose the one that best fits your needs and complexity level."
  }
]